{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_08-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-neela/neela_INFO5731_spring2021/blob/main/In_class_exercise_08_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QAjo1f-L2ql"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 3/30/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvOL2laML2qo"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4TuvKd7L2qo"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "on2X-YP3L2qp",
        "outputId": "e52e4e0d-595c-4c7c-d7b6-1b79603c7fea"
      },
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "df = pd.read_csv('Context.csv')\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_ID</th>\n",
              "      <th>Data</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Abstract not found       ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>describe a method for st...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Scaling conditional rando...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>The paper addresses the i...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>In most natural language ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Document_ID                                               Data Sentiment\n",
              "0          1.0                       Abstract not found       ...   Neutral\n",
              "1          2.0                        describe a method for st...   Neutral\n",
              "2          3.0                       Scaling conditional rando...  Negative\n",
              "3          4.0                       The paper addresses the i...  Positive\n",
              "4          5.0                       In most natural language ...  Positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPS7D1ZCqEfw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "5ade7784-9b1c-44a1-ac4b-ac3e4c8a8eb4"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from textblob import Word\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from textblob import TextBlob\n",
        "import string\n",
        "stop = stopwords.words('english')\n",
        "df['Data'] = df['Data'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "df['Data'] = df['Data'].apply(lambda  x: \" \".join(x for x in x.split() if x not in string.punctuation))\n",
        "df['Data'] = df['Data'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "df['Data'] = df['Data'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_ID</th>\n",
              "      <th>Data</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>abstract found</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>describe method statistical modeling based max...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>scaling conditional random field natural langu...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>paper address issue cooperation linguistics na...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>natural language processing applications, desc...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>96.0</td>\n",
              "      <td>paper present workbench built priberam inform√°...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>97.0</td>\n",
              "      <td>abstract‚Äînatural language processing (nlp) eff...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>98.0</td>\n",
              "      <td>abstract: twenty year disfavor, technology ret...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>99.0</td>\n",
              "      <td>text statistic frequently used stylometry cryp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>NaN</td>\n",
              "      <td>summarize experience using framenet two rather...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Document_ID                                               Data Sentiment\n",
              "0           1.0                                     abstract found   Neutral\n",
              "1           2.0  describe method statistical modeling based max...   Neutral\n",
              "2           3.0  scaling conditional random field natural langu...  Negative\n",
              "3           4.0  paper address issue cooperation linguistics na...  Positive\n",
              "4           5.0  natural language processing applications, desc...  Positive\n",
              "..          ...                                                ...       ...\n",
              "95         96.0  paper present workbench built priberam inform√°...  Positive\n",
              "96         97.0  abstract‚Äînatural language processing (nlp) eff...  Negative\n",
              "97         98.0  abstract: twenty year disfavor, technology ret...   Neutral\n",
              "98         99.0  text statistic frequently used stylometry cryp...  Positive\n",
              "99          NaN  summarize experience using framenet two rather...  Negative\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8Gq0sz0rc3t",
        "outputId": "65eab8bf-ca5b-4b18-b52e-96b94e0b3f12"
      },
      "source": [
        "from textblob import TextBlob\n",
        "words = []\n",
        "emotional_words = []\n",
        "for i in df['Data']:\n",
        "  words.append(i.split(' '))\n",
        "for i in words:\n",
        "  for j in i:\n",
        "    if TextBlob(j).sentiment.polarity != 0:\n",
        "      emotional_words.append(j)\n",
        "print(emotional_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'random', 'natural', 'natural', 'general,', 'particular.', 'natural', 'base', 'natural', 'natural', 'natural', 'subject', 'natural', 'broad', 'narrow', 'broad', 'natural', 'natural', 'natural', 'natural', 'unprocessed', 'natural', 'natural', 'natural', 'able', 'natural', 'natural', 'natural', 'natural', 'linguistic', 'directly', 'appropriate', 'natural', 'better', 'vague', 'precise', 'natural', 'natural', 'natural', 'significant', 'lyric', 'important', 'cultural', 'linguistic', 'direct', 'detailed', 'natural', 'high', 'interesting', 'new', 'natural', 'natural', 'naturally,', 'natural', 'modern', 'limited', 'behind', 'limited', 'intelligent', 'natural', 'military', 'natural', 'developed', 'base.', 'high', 'significant', 'far,', 'particular', 'much', 'particular', 'natural', 'main', 'natural', 'naturally', 'linguistic', 'natural', 'kind', 'large', 'natural', 'contemporary', 'natural', 'natural', 'new', 'relevant', 'developed', 'natural', 'natural', 'broad', 'typical', 'good', 'linguistic', 'natural', 'important', 'first', 'natural', 'natural', 'better', 'natural', 'creative,', 'many', 'complex', 'becoming', 'past', 'high', 'whole', 'whole', 'many', 'relevant', 'exact', 'general', 'special', 'subject', 'first', 'relevant', 'original', 'distinctly', 'developed', 'new', 'linguistic', 'natural', 'natural', 'natural', 'little', 'early', 'natural', 'intelligent', 'natural', 'kind', 'successful', 'natural', 'natural', 'natural', 'natural', 'empirically', 'natural', 'sophisticated', 'natural', 'important', 'many', 'natural', 'usually', 'significant', 'natural', 'natural', 'effectively', 'other,', 'natural', 'effectively', 'other,', 'natural', 'natural', 'natural', 'linguistic', 'natural', 'natural', 'effective', 'natural', 'natural', 'first', 'natural', 'mainly', 'new', 'natural', 'natural', 'typically', 'natural', 'large', 'artificial', 'many', 'foreign', 'extremely', 'popular', 'natural', 'due', 'powerful', 'unfortunately,', 'good', 'fit', 'much', 'special', 'natural', 'single', 'particular', 'natural', 'effective', 'limited', 'particular', 'typically', 'easily', 'natural', 'single', 'developed', 'advanced', 'natural', 'natural', 'new', 'natural', 'natural', 'wide', 'natural', 'natural', 'artificial', 'natural', 'wide', 'unable', 'natural', 'natural', 'previous', 'approximate', 'useful', 'wide', 'natural', 'limited', 'far', 'natural', 'natural', 'able', 'single', 'new', 'stereotypical', 'natural', 'available', 'effectively', 'usefully', 'common', 'common', 'natural', 'widely', 'powerful', 'many', 'natural', 'tedious', 'sophisticated', 'natural', 'significantly', 'general', 'past', 'natural', 'natural', 'linguistic', 'considerable', 'effective', 'educational', 'natural', 'educational', 'effective', 'natural', 'frequently', 'developed', 'natural', 'natural']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "1UfItxf10SL3",
        "outputId": "0fd4cc80-a0d5-4ca4-b8b5-abfb6a1ad2ab"
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "emotional_word_count = Counter(emotional_words)\n",
        "df_words = pd.DataFrame(list(zip(list (emotional_word_count.keys()),list (emotional_word_count.values()))), columns = ['words', 'Frequency'])\n",
        "df_words = df_words.sort_values(by=['Frequency'], ascending=False)\n",
        "df_words.insert(0, \"Rank\", np.arange(1,len(df_words)+1), True)\n",
        "df_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>words</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>natural</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>linguistic</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3</td>\n",
              "      <td>new</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>4</td>\n",
              "      <td>many</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5</td>\n",
              "      <td>developed</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>90</td>\n",
              "      <td>exact</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>91</td>\n",
              "      <td>original</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>92</td>\n",
              "      <td>distinctly</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>93</td>\n",
              "      <td>little</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>94</td>\n",
              "      <td>frequently</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>94 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Rank       words  Frequency\n",
              "0      1     natural         93\n",
              "10     2  linguistic          7\n",
              "24     3         new          6\n",
              "46     4        many          5\n",
              "31     5   developed          5\n",
              "..   ...         ...        ...\n",
              "51    90       exact          1\n",
              "54    91    original          1\n",
              "55    92  distinctly          1\n",
              "56    93      little          1\n",
              "93    94  frequently          1\n",
              "\n",
              "[94 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZiBfWM60edA",
        "outputId": "d5cab04c-146b-41d7-a027-4c80221d5819"
      },
      "source": [
        "Actual_positive = 0\n",
        "Actual_negative = 0\n",
        "Actual_neutral = 0\n",
        "for i in df['Sentiment']:\n",
        "  if i == 'Positive':\n",
        "    Actual_positive += 1\n",
        "  elif i == 'Negative':\n",
        "    Actual_negative += 1\n",
        "  elif i == 'Neutral':\n",
        "    Actual_neutral += 1\n",
        "print('Actual_positive = ', Actual_positive)\n",
        "print('Actual_negative = ', Actual_negative)\n",
        "print('Actual_neutral = ', Actual_neutral)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual_positive =  39\n",
            "Actual_negative =  27\n",
            "Actual_neutral =  33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2e_Fu9rL2qp"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ih75RWL2qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fedb8af-2cad-429d-b148-3010b7a9c9ae"
      },
      "source": [
        "# Write your code here\n",
        "from textblob import TextBlob\n",
        "positive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "for i in df['Data']:\n",
        "  sent = TextBlob(i)\n",
        "  if sent.sentiment.polarity > 0:\n",
        "    positive += 1\n",
        "  elif sent.sentiment.polarity < 0:\n",
        "    negative += 1\n",
        "  elif sent.sentiment.polarity == 0:\n",
        "    neutral += 1\n",
        "print('---------Using TextBlob-------------')\n",
        "print(\"Positive = \", positive)\n",
        "print(\"Negative = \", negative)\n",
        "print(\"Neutral = \", neutral)\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "positive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "sentimental_analyzer = SentimentIntensityAnalyzer()\n",
        "for i in df['Data']:\n",
        "  sent = TextBlob(i)\n",
        "  if sentimental_analyzer.polarity_scores(i)['compound'] > 0:\n",
        "    positive += 1\n",
        "  elif sentimental_analyzer.polarity_scores(i)['compound'] < 0:\n",
        "    negative += 1\n",
        "  elif sentimental_analyzer.polarity_scores(i)['compound'] == 0:\n",
        "    neutral += 1\n",
        "print('----------Using Vader----------------')\n",
        "print(\"Positive = \", positive)\n",
        "print(\"Negative = \", negative)\n",
        "print(\"Neutral = \", neutral)\n",
        "\n",
        "train=df[:80]\n",
        "test=df[80:]\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Create feature vectors\n",
        "vectorizer = TfidfVectorizer(min_df = 5,\n",
        "                             max_df = 0.8,\n",
        "                             sublinear_tf = True,\n",
        "                             use_idf = True)\n",
        "train_vectors = vectorizer.fit_transform(train['Data'])\n",
        "test_vectors = vectorizer.transform(test['Data'])\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "classifier_linear = svm.SVC(kernel='linear')\n",
        "t0 = time.time()\n",
        "classifier_linear.fit(train_vectors, train['Sentiment'])\n",
        "t1 = time.time()\n",
        "prediction_linear = classifier_linear.predict(test_vectors)\n",
        "t2 = time.time()\n",
        "time_linear_train = t1-t0\n",
        "time_linear_predict = t2-t1\n",
        "# results\n",
        "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
        "report = classification_report(test['Sentiment'], prediction_linear, output_dict=True)\n",
        "print('----------Using SVM----------------')\n",
        "print('Positive: ', report['Positive'])\n",
        "print('Negative: ', report['Negative'])\n",
        "print(\"Neutral:\", report['Neutral'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Your analysis here\n",
        "'''\n",
        "The correct Sentiment analysis is:\n",
        "Actual_positive =  39\n",
        "Actual_negative =  27\n",
        "Actual_neutral =  33\n",
        "\n",
        "By performing 3 modles we got below results:\n",
        "\n",
        "---------Using TextBlob-----------------------------------\n",
        "\n",
        "Positive =  74\n",
        "Negative =  10\n",
        "Neutral =  16\n",
        "\n",
        "----------Using Vader-----------------------------------\n",
        "Positive =  77\n",
        "Negative =  8\n",
        "Neutral =  15\n",
        "\n",
        "----------Using SVM-------------------------------\n",
        "Positive:  {'precision': 0.42857142857142855, 'recall': 0.3333333333333333, 'f1-score': 0.375, 'support': 9}\n",
        "Negative:  {'precision': 0.16666666666666666, 'recall': 0.25, 'f1-score': 0.2, 'support': 4}\n",
        "Neutral: {'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1-score': 0.2857142857142857, 'support': 7}\n",
        "\n",
        "So, after comparing all the methods Vader, TextBlob is more exact to that of both SVM.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------Using TextBlob-------------\n",
            "Positive =  74\n",
            "Negative =  10\n",
            "Neutral =  16\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "----------Using Vader----------------\n",
            "Positive =  77\n",
            "Negative =  8\n",
            "Neutral =  15\n",
            "Training time: 0.004308s; Prediction time: 0.000413s\n",
            "----------Using SVM----------------\n",
            "Positive:  {'precision': 0.42857142857142855, 'recall': 0.3333333333333333, 'f1-score': 0.375, 'support': 9}\n",
            "Negative:  {'precision': 0.16666666666666666, 'recall': 0.25, 'f1-score': 0.2, 'support': 4}\n",
            "Neutral: {'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1-score': 0.2857142857142857, 'support': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}