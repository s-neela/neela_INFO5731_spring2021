{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of In-class-exercise-03 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-neela/neela_INFO5731_spring2021/blob/main/Copy_of_In_class_exercise_03_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtJ1FN7yJDEN"
      },
      "source": [
        "## The third In-class-exercise (9/16/2020, 20 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDI2_Qa_JDEQ"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect the data for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2otlJESDJDEQ"
      },
      "source": [
        "Question 1 (8 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK2liU5sJDEQ"
      },
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "\n",
        "Please write you answer here:\n",
        "I'm interested in watching movies so I used to always check the IMDB rating before watching it this is where i got an idea to extracting the data of top rated movie list. I did lot of research to find a public IMDB Api and failed. \n",
        "Then I decided to screen scraping from one of the IMDB web page. I took below approach to collect the top rated movies information.\n",
        "\n",
        "1. Discovered the IMDB web page [https://www.imdb.com/chart/top] that has top rated movies, I could find the one which has 250 movies.\n",
        "2. Using `requests` library , I made a http request to get the html document from the URL.\n",
        "3. Using `BeautifulSoup` library and parsed the html document and extract the top rated movies list from html table.\n",
        "5. Using string operators Clean the data to make it usable.\n",
        "6. Converted the datarows into numpy array to convert that into pandas dataframe.\n",
        "4. Printed the dataframe and also exported to CSV.\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQdMPyYJJDER"
      },
      "source": [
        "Question 2 (12 points): Write python code to collect 500 items of the data you plan to collect above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DyN11tXJDER",
        "outputId": "fd0e5734-5d92-4432-b786-feb341f90502"
      },
      "source": [
        "# You code here (Please add comments in the code):\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Scrape Data from IMDB Website\n",
        "top_rated_movies_url = \"http://www.imdb.com/chart/top\"\n",
        "response = requests.get(top_rated_movies_url)\n",
        "htmlDocument = BeautifulSoup(response.text)\n",
        "movieTable = htmlDocument.find(\"tbody\", {\"class\":\"lister-list\"})\n",
        "movie_row = movieTable.findAll(\"tr\")\n",
        "scraped_data = [[tr.find(\"td\",{\"class\":\"titleColumn\"}).text.replace(\"\\n\",\"\"),tr.find(\"td\",{\"class\":\"ratingColumn\"}).text.replace(\"\\n\",\"\")] for tr in movie_row ]\n",
        "\n",
        "# Export Scraped Data into CSV data store  \n",
        "movie_data_rows = [ [item[0].replace(item[0][:14],\"\"), item[1]] for item in np.array(scraped_data)]\n",
        "df = pd.DataFrame(movie_data_rows, columns = ['movie_name','movie_rating'])\n",
        "df.to_csv('top_rated_movies.csv')\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            movie_name movie_rating\n",
            "0                       The Shawshank Redemption(1994)          9.2\n",
            "1                                  The Godfather(1972)          9.1\n",
            "2                         The Godfather: Part II(1974)          9.0\n",
            "3                                The Dark Knight(2008)          9.0\n",
            "4                                   12 Angry Men(1957)          8.9\n",
            "..                                                 ...          ...\n",
            "245                    A Silent Voice: The Movie(2016)          8.0\n",
            "246                                     The Help(2011)          8.0\n",
            "247    Neon Genesis Evangelion: The End of Evangeli...          8.0\n",
            "248                                   Tangerines(2013)          8.0\n",
            "249                            Three Colors: Red(1994)          8.0\n",
            "\n",
            "[250 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}